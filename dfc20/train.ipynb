{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajcWgm8fA1Z_","executionInfo":{"status":"ok","timestamp":1744996173519,"user_tz":-120,"elapsed":4815,"user":{"displayName":"krk krk","userId":"09642144202638997240"}},"outputId":"8dc5f811-ca09-409d-8541-43dc8e21ca89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/The-Role-of-Spatial-Context-in-Deep-Learning-based-Semantic-Segmentation-of-Remote-Sensing-Imagery/dfc20\n","Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\n","Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.1.31)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n","Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/The-Role-of-Spatial-Context-in-Deep-Learning-based-Semantic-Segmentation-of-Remote-Sensing-Imagery/dfc20/\n","!pip install rasterio"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sMFaNiciA1aA","executionInfo":{"status":"ok","timestamp":1744996175985,"user_tz":-120,"elapsed":3,"user":{"displayName":"krk krk","userId":"09642144202638997240"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","import numpy as np\n","import os\n","import sys\n","from torchvision import transforms\n","import time\n","\n","\n","project_root = os.getcwd()\n","sys.path.append(os.path.join(project_root, \"models\"))\n","from dataset import *\n","from models.unet import UNet"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTQahrVLA1aB","executionInfo":{"status":"ok","timestamp":1744998406605,"user_tz":-120,"elapsed":106,"user":{"displayName":"krk krk","userId":"09642144202638997240"}},"outputId":"029b3762-41ba-4611-8631-195fd479594c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[Load]: 100%|██████████| 4270/4270 [00:00<00:00, 375724.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["loaded 4270 samples from the DFC20 subset train\n"]},{"output_type":"stream","name":"stderr","text":["[Load]: 100%|██████████| 684/684 [00:00<00:00, 353879.85it/s]"]},{"output_type":"stream","name":"stdout","text":["loaded 684 samples from the DFC20 subset val\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["############ LOAD DATA ############\n","\n","path = \"./data\"\n","\n","# load datasets\n","train_set = DFC20(path,\n","                  subset=\"train\",\n","                  use_s1=False,\n","                  use_s2_RGB=True,\n","                  use_s2_hr=False,\n","                  use_s2_all=False,\n","                  as_tensor=True)\n","\n","val_set = DFC20(path,\n","                subset=\"val\",\n","                use_s1=False,\n","                use_s2_RGB=True,\n","                use_s2_hr=False,\n","                use_s2_all=False,\n","                as_tensor=True)\n","\n","n_inputs = train_set.n_inputs\n","\n","# tuned hyperparams\n","batch_size = 8\n","num_workers = 4\n","prefetch_factor = 2\n","\n","num_epochs = 3\n","learning_rate = 1e-4\n","scheduler_factor = 0.5\n","scheduler_patience = 3\n","\n","# set up dataloaders\n","train_loader = DataLoader(train_set,\n","                            batch_size=batch_size,\n","                            shuffle=True,\n","                            pin_memory=True,\n","                            drop_last=False,\n","                            num_workers=num_workers,\n","                            prefetch_factor=prefetch_factor)\n","\n","val_loader = DataLoader(train_set,\n","                            batch_size=batch_size,\n","                            shuffle=True,\n","                            pin_memory=True,\n","                            drop_last=False,\n","                            num_workers=num_workers,\n","                            prefetch_factor=prefetch_factor)\n","\n"]},{"cell_type":"code","source":["############ MODEL CHOICE ############\n","\n","model = UNet(n_channels=n_inputs)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ryQ4Lc2NcYL","executionInfo":{"status":"ok","timestamp":1744998409553,"user_tz":-120,"elapsed":209,"user":{"displayName":"krk krk","userId":"09642144202638997240"}},"outputId":"4963f62c-1963-44ec-c42c-a02f039d2125"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtEECzoeA1aC"},"outputs":[],"source":["############ TRAIN ############\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()  # maybe dice, maybe weights?\n","\n","# Optimizer\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Scheduler\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='min', factor=scheduler_factor, patience=scheduler_patience, verbose=True\n",")\n","\n","# mIoU helper\n","def compute_miou(pred, label, num_classes):\n","    ious = []\n","    pred = pred.view(-1)\n","    label = label.view(-1)\n","    for cls in range(num_classes):\n","        pred_inds = (pred == cls)\n","        label_inds = (label == cls)\n","        intersection = (pred_inds & label_inds).sum().item()\n","        union = (pred_inds | label_inds).sum().item()\n","        if union == 0:\n","            ious.append(float('nan'))  # or 0.0\n","        else:\n","            ious.append(intersection / union)\n","    return sum([iou for iou in ious if not torch.isnan(torch.tensor(iou))]) / num_classes\n","\n","# Training loop\n","writer = SummaryWriter(log_dir='logs/param_tuning') # param_tuning, baseline, ...\n","best_val_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    epoch_start = time.time()\n","    model.train()\n","    running_loss = 0.0\n","    total_accuracy = 0.0\n","    total_miou = 0.0\n","    num_batches = 0\n","\n","    load_start = time.time()\n","\n","    for batch in train_loader:\n","        load_end = time.time()\n","        data_loading_time = load_end - load_start\n","        batch_start = time.time()\n","\n","        # unpack sample\n","        inputs = batch['image'].to(device)\n","        labels = batch['label'].to(device)\n","        # reset gradients\n","        optimizer.zero_grad()\n","        # forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        # backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # prediction\n","        predicted_labels = torch.argmax(outputs, dim=1)\n","        # Accuracy\n","        accuracy = (predicted_labels == labels).float().mean().item() * 100\n","        total_accuracy += accuracy\n","        # mIoU\n","        miou = compute_miou(predicted_labels, labels, num_classes=outputs.shape[1])\n","        total_miou += miou\n","\n","        num_batches += 1\n","\n","        batch_time = time.time() - batch_start\n","\n","        print(f\"[Batch {num_batches}] Load: {data_loading_time:.2f}s | Batch: {batch_time:.2f}s\")\n","\n","        load_start = time.time()\n","\n","    avg_loss = running_loss / len(train_loader)\n","    avg_accuracy = total_accuracy / num_batches\n","    avg_miou = total_miou / num_batches\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_accuracy = 0.0\n","    val_miou = 0.0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            inputs = batch['image'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            predicted = torch.argmax(outputs, dim=1)\n","            acc = (predicted == labels).float().mean().item() * 100\n","            miou = compute_miou(predicted, labels, num_classes=outputs.shape[1])\n","            val_accuracy += acc\n","            val_miou += miou\n","\n","    val_loss /= len(val_loader)\n","    val_accuracy /= len(val_loader)\n","    val_miou /= len(val_loader)\n","\n","    scheduler.step(val_loss)\n","\n","    # Print epoch summary\n","    epoch_time = time.time() - epoch_start\n","    print(f\"\\n=== Epoch {epoch+1}/{num_epochs} — {epoch_time:.2f}s ===\")\n","    print(f\"Train     — Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2f}%, mIoU: {avg_miou:.4f}\")\n","    print(f\"Validate  — Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%, mIoU: {val_miou:.4f}\\n\")\n","\n","    # TensorBoard logging\n","    writer.add_scalar('Loss/train', avg_loss, epoch)\n","    writer.add_scalar('Accuracy/train', avg_accuracy, epoch)\n","    writer.add_scalar('mIoU/train', avg_miou, epoch)\n","    writer.add_scalar('Loss/val', val_loss, epoch)\n","    writer.add_scalar('Accuracy/val', val_accuracy, epoch)\n","    writer.add_scalar('mIoU/val', val_miou, epoch)\n","    writer.add_scalar('LearningRate', optimizer.param_groups[0]['lr'], epoch)\n","\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        # torch.save(model.state_dict(), 'trained_models/unet_baseline.pth')\n","\n","writer.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsaAfAR0A1aD"},"outputs":[],"source":["############ TRAIN LOGS ############\n","\n","%load_ext tensorboard\n","%tensorboard --logdir=runs"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}